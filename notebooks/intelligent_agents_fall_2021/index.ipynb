{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook we will discuss the nature of intelligent agents and we will try to describe an agent behavior with an mathematic notation.\n",
    "we will begin by "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent agents\n",
    "An <b>intelligent agent</b> is anything which perceives its environment through sensors and acts upon that enviroment through its actuators.  \n",
    "    we will use the term <b>percept</b> to refer to the agent's perceptual inputs at any given moment.\n",
    "we can describe an agent's behavior by the agent function.  \n",
    "<b>agent function</b> maps any given pecepts sequence to an action. but how does the agent know what sequence it must choose? we wil try to answer this question using a simple example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### vacumm world agent example\n",
    "<img src=\"./images/vacumm_world.png\" width=\"500\" style=\"margin-left: auto;margin-right: auto;\"/>\n",
    "Imagine an enivroment which only has two rooms (room A & room B). our agent is a vacumm cleaner. it can perceive wheter the room it is currently in, is dirty or not. it can also move beetwen the rooms and suck up dirt (the actuators of the agent).  \n",
    "Imagine that we only care about both rooms being clean, a simple way we can implement an agent that garantees this is for out agent to constanly move beetwen the rooms and suck up dirt in each one. Now imagine we also want to minimze the amount of energy the vcuum cleaner uses. In order to do that we can stop the agent for a limited amount of time if both rooms are clean. as you can see we implemented two compltly different agent for these two problems and thats because we used two different performance measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rational agents and performance measure\n",
    "a <b>rational</b> agent choose the set of action in order to maximize its performance. agents use a performance measure to evaluate the desirability of any given sequence. In other words an agent will choose the action (or a sequence of them) that maximize the expected value of its performance measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rationality vs perfection\n",
    "Keep in mind that rationality is distinct from omnniscience. an omniscience agent knows the actual outcome of its actions but in reality an agent only knows the expected outcome of its action.\n",
    "#### autonomy\n",
    "a rational agent should be autonomus meaning it musn't only rely on the prior knowledge of its designer and must learn to compensate for partial or incorrect prior knowledge. In other words rational agents should learn from expreince. for example in the vacumm world our agent could start to learn when the rooms usually get dirty based on its expreince."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task enviroments (PEAS)\n",
    "we have already talked about performance measure, task enviroment, actuators and sensors. we group all these under the heading of the <b>Task enviroment </b> and we abbreviate it as <b>PEAS</b>(<b>P</b>erformance measure, <b>E</b>nviroment, <b>A</b>ctuators, <b>S</b>ensors). When designing an agent our first step should be specifying the task enviroment.\n",
    "#### Types of enviroment\n",
    "<ul>\n",
    "  <li><b>Fully observable or partially observable</b> (do the agent sensors give access to the complete state of the environment at each time?)</li>\n",
    "  <li><b>Single agent or multiagent</b> (are there more than one agent in the enviroment?)</li>\n",
    "  <li><b>Deterministic or stochastic</b> (is the next state completely determined by the current state and the executed action?)</li>\n",
    "  <li><b>Episodic or sequential</b> (is the agent's experience divided into atomic \"episodesâ€œ where the choice of action in each episode depends only on the episode itself?)</li>\n",
    "  <li><b>Discrete or continuous</b> (are there a limited number of distinct, clearly defined states, percepts and actions?)</li>  \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PEAS example\n",
    "here are a few example of specifying PEAS for an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
