{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <h1 style=\"font-size: 40px; margin: 10px 0;\">AI - Intelligent Agent</h1>\n",
    "    <h1 style=\"font-size: 20px; font-weight: 400;\">Sharif University of Technology - Computer Engineering Department</h1>\n",
    "    <br>\n",
    "    <h4 style=\"font-size: 18px; font-weight: 400; color:#555\">Amirreza Mirzaei, Bardia Mohammadi, Sina Elahimanesh</h4>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Table of contents\n",
    "==============\n",
    "- [Introduction](#Introduction)\n",
    "- [Intelligent agents](#Intelligent-agents)\n",
    "    - [Vacuum world agent example](#Vacuum-world-agent-example)\n",
    "- [Rational agents and performance measure](#Rational-agents-and-performance-measure)\n",
    "    - [Rationality vs perfection](#Rationality-vs-perfection)\n",
    "    - [Autonomy](#Autonomy)\n",
    "- [Task environment (PEAS)](#Task-environment-(PEAS))\n",
    "    - [Types of environment](#Types-of-environment)\n",
    "    - [PEAS example](#PEAS-example)\n",
    "- [Type of agents](#Type-of-agents)\n",
    "    - [Reflex agents](#Reflex-agents)\n",
    "    - [Goal-based agents](#Goal-based-agents)\n",
    "    - [Utility-based agents](#Utility-based-agents)\n",
    "- [Conclusion](#Conclusion)\n",
    "- [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook we will discuss the nature of intelligent agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent agents\n",
    "An <b>intelligent agent</b> is anything that perceives its environment through sensors and acts upon that environment through its actuators.  \n",
    "    we will use the term <b>percept</b> to refer to the agent's perceptual inputs at any given moment.\n",
    "we can describe an agent's behavior by the agent function.  \n",
    "<b>agent function</b> maps any given percepts sequence to an action. but how does the agent know what sequence it must choose? we will try to answer this question using a simple example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vacuum world agent example\n",
    "<img src=\"./images/vacumm_world.png\" width=\"500\" style=\"margin-left: auto;margin-right: auto;\"/>\n",
    "Imagine an environment that only has two rooms (room A & room B). our agent is a vacuum cleaner. it can perceive whether the room it is currently in, is dirty or not. it can also move between the rooms and suck up dirt (the actuators of the agent).  \n",
    "Imagine that we only care about both rooms being clean, a simple way we can implement an agent that guarantees this is for our agent to constantly move between the rooms and suck up dirt in each one. Now imagine we also want to minimize the amount of energy the vacuum cleaner uses. In order to do that we can stop the agent for a limited amount of time if both rooms are clean. as you can see we implemented two completely different agents for these two problems and that's because we used two different performance measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rational agents and performance measure\n",
    "a <b>rational</b> agent choose the set of action in order to maximize its performance. agents use a performance measure to evaluate the desirability of any given sequence. In other words, an agent will choose the action (or a sequence of them) that maximize the expected value of its performance measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rationality vs perfection\n",
    "Keep in mind that rationality is distinct from omniscience. an omniscience agent knows the actual outcome of its actions but in reality, an agent only knows the expected outcome of its action.\n",
    "#### Autonomy\n",
    "a rational agent should be autonomous meaning it mustn't only rely on the prior knowledge of its designer and must learn to compensate for partial or incorrect prior knowledge. In other words, rational agents should learn from experience. for example, in the vacuum world our agent could start to learn when the rooms usually get dirty based on its experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task environment (PEAS)\n",
    "we have already talked about performance measure, task environment, actuators and sensors. we group all these under the heading of the <b>Task enviroment </b> and we abbreviate it as <b>PEAS</b>(<b>P</b>erformance measure, <b>E</b>nviroment, <b>A</b>ctuators, <b>S</b>ensors). When designing an agent our first step should be specifying the task enviroment.\n",
    "#### Types of environment\n",
    "<ul>\n",
    "  <li><b>Fully observable or partially observable</b> (do the agent sensors give access to the complete state of the environment at each time?)</li>\n",
    "  <li><b>Single agent or multiagent</b> (are there more than one agent in the enviroment?)</li>\n",
    "  <li><b>Deterministic or stochastic</b> (is the next state completely determined by the current state and the executed action?)</li>\n",
    "  <li><b>Episodic or sequential</b> (is the agent's experience divided into atomic \"episodes“ where the choice of action in each episode depends only on the episode itself?)</li>\n",
    "  <li><b>Discrete or continuous</b> (are there a limited number of distinct, clearly defined states, percepts and actions?)</li>  \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PEAS example\n",
    "here are a few example of specifying PEAS for different agents.\n",
    "<figure class=\"table\"><table><thead><tr><th><strong>Agent</strong></th><th><strong>Performance Measure</strong></th><th><strong>Environment</strong></th><th><strong>Actuator</strong></th><th><strong>Sensor</strong></th></tr></thead><tbody><tr><td>Hospital Management System</td><td class=\"\">Patient’s health, Admission process, Payment</td><td>Hospital, Doctors, Patients</td><td>Prescription, Diagnosis, Scan report</td><td>Symptoms, Patient’s response</td></tr><tr><td>Automated Car Drive</td><td>Comfortable trip, Safety, Maximum Distance</td><td>Roads, Traffic, Vehicles</td><td>Steering wheel, Accelerator, Brake, Mirror</td><td>Camera, GPS, Odometer</td></tr><tr><td>Subject Tutoring</td><td>Maximize scores, Improvement is students</td><td>Classroom, Desk, Chair, Board, Staff, Students</td><td>Smart displays, Corrections</td><td>Eyes, Ears, Notebooks</td></tr></tbody></table></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type of agents\n",
    "In this section we will introduce three basic kinds of basic agent programs.(The agent program is simply a program which implement the agent function.)\n",
    "<ul>\n",
    "  <li>Simple reflex agents</li>\n",
    "  <li>Goal-based agents</li>\n",
    "  <li>Utility-based agents</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflex agents\n",
    "This is the simplest kind of agent. they choose their next action only based on their current percept. In other words, they do not consider the future consequences of their actions and only consider <b>how the world IS.</b>  \n",
    "as an example look at this Pacman agent below at each turn the agent look at its surrounding and chooses the direction that has a point in it and stops when there are no points around it.\n",
    "\n",
    "<img src=\"./images/reflex_agent.gif\" width=\"500\" style=\"margin-left: auto;margin-right: auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal-based agents\n",
    "This kind of agent has a specific goal and its tries to reach that goal efficiently. They have a model of how the world evolves in response to actions and they make decisions based on (hypothesized) consequences of actions to reach their goal state. Search and Planning are two subfields that are closely tied with these kind of agents. In other words, this kinds of agents act on <b>how the world WOULD BE.</b>  \n",
    "as an example look at this Pacman agent below. the goal is to collect every point.\n",
    "\n",
    "<img src=\"./images/goal_based_agent.gif\" width=\"500\" style=\"margin-left: auto;margin-right: auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility-based agents\n",
    "This kind of agent like goal-based agents has a goal. but they also have a Utility function they seek to reach their goal in a way that maximizes the utility function. for example, think about an automated car agent. they are many ways for this agent to get from point A to point B. but some of them are quicker, safer, cheaper. The utility function allows the agent to compare different states with each other and ask the question how happy am I in this state. \n",
    "In other words, this kind of agent act on <b>how the world will LIKELY be.</b>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "you should know about these topics after reading this note.\n",
    "<ul>\n",
    "    <li>Intelligent agents</li>\n",
    "    <li>Performance measure</li>\n",
    "    <li>Task enviroment(PEAS)</li>\n",
    "    <li>Types of agents</li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "+ Russell, S. J., Norvig, P., &amp; Davis, E. (2022). Artificial Intelligence: A modern approach. Pearson Educación. \n",
    "+ UC Berkeley's introductory artificial intelligence course, CS 188\n",
    "+ https://www.geeksforgeeks.org/understanding-peas-in-artificial-intelligence/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}